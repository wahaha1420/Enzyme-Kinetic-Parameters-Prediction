{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECNumber</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Substrate</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Raw Kd</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Log Kd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2.3.4</td>\n",
       "      <td>Actinidia chinensis</td>\n",
       "      <td>C(C(C(C(COP(=O)(O)O)O)O)O)C(=O)C(=O)O</td>\n",
       "      <td>3-deoxy-D-arabino-heptulosonic acid 7-phosphate</td>\n",
       "      <td>MAAFSLSAKQILSPSTHRPSLSKTTTADSSLRFRNPHSLSLRCSSL...</td>\n",
       "      <td>20.1000</td>\n",
       "      <td>s^(-1)</td>\n",
       "      <td>1.303196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2.3.4</td>\n",
       "      <td>Aspergillus nidulans</td>\n",
       "      <td>C(C(C(C(COP(=O)([O-])[O-])O)O)O)C(=O)C(=O)[O-]</td>\n",
       "      <td>3-deoxy-D-arabino-heptulosonate 7-phosphate</td>\n",
       "      <td>MSNPTKISILGRESIIADFGLWRNYVAKDLISDCSSTTYVLVTDTN...</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>s^(-1)</td>\n",
       "      <td>0.832509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.2.3.4</td>\n",
       "      <td>Neurospora crassa</td>\n",
       "      <td>C(C(C(C(COP(=O)(O)O)O)O)O)C(=O)C(=O)O</td>\n",
       "      <td>3-deoxy-D-arabino-heptulosonic acid 7-phosphate</td>\n",
       "      <td>MAEPISNPTRINILGKDNIIIDHGIWLNFVAQDLLQNIKSSTYILI...</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>s^(-1)</td>\n",
       "      <td>1.278754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1.1.255</td>\n",
       "      <td>Streptomyces coelicolor</td>\n",
       "      <td>C[S+](CCC(C(=O)[O-])N)CC1C(C(C(O1)N2C=NC3=C(N=...</td>\n",
       "      <td>S-Adenosyl-L-methionine</td>\n",
       "      <td>MTTETTTATATAKIPAPATPYQEDIARYWNNEARPVNLRLGDVDGL...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>s^(-1)</td>\n",
       "      <td>-2.124939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1.1.255</td>\n",
       "      <td>Streptomyces coelicolor</td>\n",
       "      <td>CC(=CCCC(=C(C)COP(=O)(O)OP(=O)(O)O)C)C</td>\n",
       "      <td>(E)-2-Methylgeranyl diphosphate</td>\n",
       "      <td>MTTETTTATATAKIPAPATPYQEDIARYWNNEARPVNLRLGDVDGL...</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>s^(-1)</td>\n",
       "      <td>-1.408935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ECNumber                 Organism  \\\n",
       "0    4.2.3.4      Actinidia chinensis   \n",
       "1    4.2.3.4     Aspergillus nidulans   \n",
       "2    4.2.3.4        Neurospora crassa   \n",
       "3  2.1.1.255  Streptomyces coelicolor   \n",
       "4  2.1.1.255  Streptomyces coelicolor   \n",
       "\n",
       "                                              Smiles  \\\n",
       "0              C(C(C(C(COP(=O)(O)O)O)O)O)C(=O)C(=O)O   \n",
       "1     C(C(C(C(COP(=O)([O-])[O-])O)O)O)C(=O)C(=O)[O-]   \n",
       "2              C(C(C(C(COP(=O)(O)O)O)O)O)C(=O)C(=O)O   \n",
       "3  C[S+](CCC(C(=O)[O-])N)CC1C(C(C(O1)N2C=NC3=C(N=...   \n",
       "4             CC(=CCCC(=C(C)COP(=O)(O)OP(=O)(O)O)C)C   \n",
       "\n",
       "                                         Substrate  \\\n",
       "0  3-deoxy-D-arabino-heptulosonic acid 7-phosphate   \n",
       "1      3-deoxy-D-arabino-heptulosonate 7-phosphate   \n",
       "2  3-deoxy-D-arabino-heptulosonic acid 7-phosphate   \n",
       "3                          S-Adenosyl-L-methionine   \n",
       "4                  (E)-2-Methylgeranyl diphosphate   \n",
       "\n",
       "                                            Sequence   Raw Kd    Unit  \\\n",
       "0  MAAFSLSAKQILSPSTHRPSLSKTTTADSSLRFRNPHSLSLRCSSL...  20.1000  s^(-1)   \n",
       "1  MSNPTKISILGRESIIADFGLWRNYVAKDLISDCSSTTYVLVTDTN...   6.8000  s^(-1)   \n",
       "2  MAEPISNPTRINILGKDNIIIDHGIWLNFVAQDLLQNIKSSTYILI...  19.0000  s^(-1)   \n",
       "3  MTTETTTATATAKIPAPATPYQEDIARYWNNEARPVNLRLGDVDGL...   0.0075  s^(-1)   \n",
       "4  MTTETTTATATAKIPAPATPYQEDIARYWNNEARPVNLRLGDVDGL...   0.0390  s^(-1)   \n",
       "\n",
       "     Log Kd  \n",
       "0  1.303196  \n",
       "1  0.832509  \n",
       "2  1.278754  \n",
       "3 -2.124939  \n",
       "4 -1.408935  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load('TrainingDataset/Kcat_Enzymatic_reaction.pt',weights_only=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load ChemRoBERTa tokenizer and model\n",
    "chem_tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "chem_model = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "# Load ESM2 tokenizer and model\n",
    "esm_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "esm_model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique mols and proteins\n",
    "unique_mols = data[['Smiles']].drop_duplicates()\n",
    "unique_proteins = data[['Sequence']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chem_features(smiles):\n",
    "    \"\"\"Extract ChemRoBERTa features from SMILES.\"\"\"\n",
    "    try:\n",
    "        tokens = chem_tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            embeddings = chem_model(**tokens).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "    except:\n",
    "        return np.zeros(768)  # Return zero vector if extraction fails\n",
    "\n",
    "def extract_esm_features(sequence):\n",
    "    \"\"\"Extract ESM2 features from protein sequence.\"\"\"\n",
    "    try:\n",
    "        tokens = esm_tokenizer(sequence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            embeddings = esm_model(**tokens).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "    except:\n",
    "        return np.zeros(768)  # Return zero vector if extraction fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2706/2706 [00:45<00:00, 59.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for unique mols\n",
    "tqdm.pandas()  # Enable progress bar for pandas\n",
    "unique_mols['metabolite_features'] = unique_mols['Smiles'].progress_apply(extract_chem_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7857 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 7857/7857 [07:01<00:00, 18.63it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Extract features for unique proteins\n",
    "unique_proteins['protein_features'] = unique_proteins['Sequence'].progress_apply(extract_esm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features back into the combined dataframe\n",
    "data = data.merge(unique_mols, on='Smiles', how='left')\n",
    "data = data.merge(unique_proteins, on='Sequence', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = -np.log10(data['Raw Kd'] + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "class MPI_Dataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        return {\n",
    "            'metabolite_features': torch.tensor(np.asarray(row['metabolite_features'], dtype=np.float32)),\n",
    "            'protein_features': torch.tensor(np.asarray(row['protein_features'], dtype=np.float32)),\n",
    "            'label': torch.tensor(float(row['label']), dtype=torch.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(data, test_size=0.3, shuffle=True, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = MPI_Dataset(train_df)\n",
    "val_dataset = MPI_Dataset(val_df)\n",
    "test_dataset = MPI_Dataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X = np.array([\n",
    "    np.concatenate([m, p])\n",
    "    for m, p in zip(train_df['metabolite_features'], train_df['protein_features'])\n",
    "])\n",
    "train_y = train_df['label']\n",
    "val_X = np.array([\n",
    "    np.concatenate([m, p])\n",
    "    for m, p in zip(val_df['metabolite_features'], val_df['protein_features'])\n",
    "])\n",
    "val_y = val_df['label']\n",
    "test_X = np.array([\n",
    "    np.concatenate([m, p])\n",
    "    for m, p in zip(test_df['metabolite_features'], test_df['protein_features'])\n",
    "])\n",
    "test_y = test_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define MLP Model for Regression\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, mol_input_dim, protein_input_dim, hidden_dim=128):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "\n",
    "        self.mol_encoder = nn.Linear(mol_input_dim, hidden_dim)\n",
    "        self.protein_encoder = nn.Linear(protein_input_dim, hidden_dim)\n",
    "        \n",
    "        # norm layer + Dropout\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # hidden layer + output layer\n",
    "        self.hidden = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.regressor = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, mol_input, protein_input):\n",
    "        # Reshape to (B, 1, L) for Conv1d\n",
    "        mol_embedding = self.activation(self.mol_encoder(mol_input))\n",
    "        protein_embedding = self.activation(self.protein_encoder(protein_input))\n",
    "\n",
    "        # Concatenate + Normalize + Dropout\n",
    "        combined = torch.cat((mol_embedding, protein_embedding), dim=-1)\n",
    "        combined = self.layer_norm(combined)\n",
    "        combined = self.dropout(combined)\n",
    "\n",
    "        # Hidden → Regress\n",
    "        hidden_out = self.activation(self.hidden(combined))\n",
    "        output = self.regressor(hidden_out)\n",
    "\n",
    "        return output.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cold mols models\n",
    "import torch\n",
    "import joblib\n",
    "for batch in test_loader:\n",
    "    mol_input_dim = batch['metabolite_features'].shape[1]\n",
    "    protein_input_dim = batch['protein_features'].shape[1]\n",
    "    break  \n",
    "mlp = MLPRegressor(mol_input_dim=mol_input_dim, protein_input_dim=protein_input_dim,hidden_dim=512)\n",
    "mlp.load_state_dict(torch.load('/Users/pinchichen/2025S lab/AI drug project/code/trained_model/MLP model.pt'))\n",
    "rf = joblib.load('/Users/pinchichen/2025S lab/AI drug project/code/trained_model/RF model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error, explained_variance_score\n",
    "from scipy.stats import pearsonr\n",
    "def evaluate_model(predictions, labels):\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)\n",
    "    medae = median_absolute_error(labels, predictions)\n",
    "    evs = explained_variance_score(labels, predictions)\n",
    "\n",
    "    return mse, rmse, mae, r2, pearson_corr, medae, evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "train_pred_mlp, train_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        mol_features = batch['metabolite_features'].to(device)\n",
    "        protein_features = batch['protein_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = mlp(mol_features, protein_features)\n",
    "        train_pred_mlp.extend(outputs.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "train_pred_rf = rf.predict(train_X)\n",
    "train_pred_final = (train_pred_mlp + train_pred_rf) / 2.0\n",
    "train_mse, train_rmse, train_mae, train_r2, train_pearson_corr, train_median_ae, train_explained_var = evaluate_model(train_pred_final, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "val_pred_mlp, val_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        mol_features = batch['metabolite_features'].to(device)\n",
    "        protein_features = batch['protein_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = mlp(mol_features, protein_features)\n",
    "        val_pred_mlp.extend(outputs.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "val_pred_rf = rf.predict(val_X)\n",
    "val_pred_final = (val_pred_mlp + val_pred_rf) / 2.0\n",
    "val_mse, val_rmse, val_mae, val_r2, val_pearson_corr, val_median_ae, val_explained_var = evaluate_model(val_pred_final, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "test_pred_mlp, test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        mol_features = batch['metabolite_features'].to(device)\n",
    "        protein_features = batch['protein_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = mlp(mol_features, protein_features)\n",
    "        test_pred_mlp.extend(outputs.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rf = rf.predict(test_X)\n",
    "pred_final = (test_pred_mlp + test_pred_rf) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.0914, MAE: 0.7230, R-square: 0.5150\n"
     ]
    }
   ],
   "source": [
    "#Choose the best model and test its performance\n",
    "\n",
    "#best_model = regressor.best_estimator_\n",
    "#best_params = regressor.best_params_\n",
    "#print('Best Hyperparameters:',best_params)\n",
    "\n",
    "# Test\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error, explained_variance_score\n",
    "from scipy.stats import pearsonr\n",
    "test_mse = mean_squared_error(test_y, pred_final)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(test_y, pred_final)\n",
    "test_r2 = r2_score(test_y, pred_final)\n",
    "test_pearson_corr, _ = pearsonr(test_y, pred_final)\n",
    "test_median_ae = median_absolute_error(test_y, pred_final)\n",
    "test_explained_var = explained_variance_score(test_y, pred_final)\n",
    "\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R-square: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# append the performance to the csv file\n",
    "df = {\n",
    "    'Model':['ensemble', 'ensemble', 'ensemble'],\n",
    "    'Dataset':['Train', 'Validation', 'Test'],\n",
    "    'MSE':[train_mse, val_mse, test_mse],\n",
    "    'RMSE':[train_rmse, val_rmse, test_rmse],\n",
    "    'MAE':[train_mae, val_mae, test_mae],\n",
    "    'R2':[train_r2, val_r2, test_r2],\n",
    "    'Pearson':[train_pearson_corr, val_pearson_corr, test_pearson_corr],\n",
    "    'Median_AE':[train_median_ae, val_median_ae, test_median_ae],\n",
    "    'Explained_VAR':[train_explained_var, val_explained_var, test_explained_var],\n",
    "    'Dataspliting Mode':['random','random','random']\n",
    "}\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df.to_csv('/Users/pinchichen/2025S lab/AI drug project/code/model performance metrics.csv', mode='a', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
